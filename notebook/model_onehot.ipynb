{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2347e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pickle import dump, load\n",
    "\n",
    "# Load the dataset\n",
    "df_income = pd.read_csv(\"../Data/income_evaluation_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3aa1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_cat = ['workclass',\n",
    " 'education',\n",
    " 'marital-status',\n",
    " 'occupation',\n",
    " 'relationship',\n",
    " 'race',\n",
    " 'sex',\n",
    " 'native-country']\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d353041b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30157</th>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30160</th>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  hours-per-week  income  workclass_ Federal-gov  \\\n",
       "0       39              40   <=50K                     0.0   \n",
       "1       50              13   <=50K                     0.0   \n",
       "2       38              40   <=50K                     0.0   \n",
       "3       53              40   <=50K                     0.0   \n",
       "4       28              40   <=50K                     0.0   \n",
       "...    ...             ...     ...                     ...   \n",
       "30157   27              38   <=50K                     0.0   \n",
       "30158   40              40    >50K                     0.0   \n",
       "30159   58              40   <=50K                     0.0   \n",
       "30160   22              20   <=50K                     0.0   \n",
       "30161   52              40    >50K                     0.0   \n",
       "\n",
       "       workclass_ Local-gov  workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                       0.0                 0.0                      0.0   \n",
       "1                       0.0                 0.0                      0.0   \n",
       "2                       0.0                 1.0                      0.0   \n",
       "3                       0.0                 1.0                      0.0   \n",
       "4                       0.0                 1.0                      0.0   \n",
       "...                     ...                 ...                      ...   \n",
       "30157                   0.0                 1.0                      0.0   \n",
       "30158                   0.0                 1.0                      0.0   \n",
       "30159                   0.0                 1.0                      0.0   \n",
       "30160                   0.0                 1.0                      0.0   \n",
       "30161                   0.0                 0.0                      1.0   \n",
       "\n",
       "       workclass_ Self-emp-not-inc  workclass_ State-gov  \\\n",
       "0                              0.0                   1.0   \n",
       "1                              1.0                   0.0   \n",
       "2                              0.0                   0.0   \n",
       "3                              0.0                   0.0   \n",
       "4                              0.0                   0.0   \n",
       "...                            ...                   ...   \n",
       "30157                          0.0                   0.0   \n",
       "30158                          0.0                   0.0   \n",
       "30159                          0.0                   0.0   \n",
       "30160                          0.0                   0.0   \n",
       "30161                          0.0                   0.0   \n",
       "\n",
       "       workclass_ Without-pay  ...  native-country_ Portugal  \\\n",
       "0                         0.0  ...                       0.0   \n",
       "1                         0.0  ...                       0.0   \n",
       "2                         0.0  ...                       0.0   \n",
       "3                         0.0  ...                       0.0   \n",
       "4                         0.0  ...                       0.0   \n",
       "...                       ...  ...                       ...   \n",
       "30157                     0.0  ...                       0.0   \n",
       "30158                     0.0  ...                       0.0   \n",
       "30159                     0.0  ...                       0.0   \n",
       "30160                     0.0  ...                       0.0   \n",
       "30161                     0.0  ...                       0.0   \n",
       "\n",
       "       native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                              0.0                       0.0   \n",
       "1                              0.0                       0.0   \n",
       "2                              0.0                       0.0   \n",
       "3                              0.0                       0.0   \n",
       "4                              0.0                       0.0   \n",
       "...                            ...                       ...   \n",
       "30157                          0.0                       0.0   \n",
       "30158                          0.0                       0.0   \n",
       "30159                          0.0                       0.0   \n",
       "30160                          0.0                       0.0   \n",
       "30161                          0.0                       0.0   \n",
       "\n",
       "       native-country_ South  native-country_ Taiwan  \\\n",
       "0                        0.0                     0.0   \n",
       "1                        0.0                     0.0   \n",
       "2                        0.0                     0.0   \n",
       "3                        0.0                     0.0   \n",
       "4                        0.0                     0.0   \n",
       "...                      ...                     ...   \n",
       "30157                    0.0                     0.0   \n",
       "30158                    0.0                     0.0   \n",
       "30159                    0.0                     0.0   \n",
       "30160                    0.0                     0.0   \n",
       "30161                    0.0                     0.0   \n",
       "\n",
       "       native-country_ Thailand  native-country_ Trinadad&Tobago  \\\n",
       "0                           0.0                              0.0   \n",
       "1                           0.0                              0.0   \n",
       "2                           0.0                              0.0   \n",
       "3                           0.0                              0.0   \n",
       "4                           0.0                              0.0   \n",
       "...                         ...                              ...   \n",
       "30157                       0.0                              0.0   \n",
       "30158                       0.0                              0.0   \n",
       "30159                       0.0                              0.0   \n",
       "30160                       0.0                              0.0   \n",
       "30161                       0.0                              0.0   \n",
       "\n",
       "       native-country_ United-States  native-country_ Vietnam  \\\n",
       "0                                1.0                      0.0   \n",
       "1                                1.0                      0.0   \n",
       "2                                1.0                      0.0   \n",
       "3                                1.0                      0.0   \n",
       "4                                0.0                      0.0   \n",
       "...                              ...                      ...   \n",
       "30157                            1.0                      0.0   \n",
       "30158                            1.0                      0.0   \n",
       "30159                            1.0                      0.0   \n",
       "30160                            1.0                      0.0   \n",
       "30161                            1.0                      0.0   \n",
       "\n",
       "       native-country_ Yugoslavia  \n",
       "0                             0.0  \n",
       "1                             0.0  \n",
       "2                             0.0  \n",
       "3                             0.0  \n",
       "4                             0.0  \n",
       "...                           ...  \n",
       "30157                         0.0  \n",
       "30158                         0.0  \n",
       "30159                         0.0  \n",
       "30160                         0.0  \n",
       "30161                         0.0  \n",
       "\n",
       "[30162 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_income[income_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(income_cat)\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "df_income = df_income.merge(encode_df, left_index=True, right_index=True).drop(income_cat,1)\n",
    "df_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948cfd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = df_income.drop(columns='income').values\n",
    "y = df_income['income'].values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "### Define the scaling function \n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the training set\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "\n",
    "\n",
    "# Define the label encoder and fit it to the training set\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "# Transform the labels of the training set\n",
    "y_train_encoded = le.transform(y_train)\n",
    "\n",
    "### Define the model\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48e9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a pickle file (i.e., \"pickle it\")\n",
    "# so we can use it from the Flask server. \n",
    "dump(model, open('logisticregression.pkl', 'wb'))\n",
    "\n",
    "# Save the scaling function to a pickle file (i.e., \"pickle it\")\n",
    "# so we can use it from the Flask server. \n",
    "dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b15be51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education marital-status    occupation   relationship  \\\n",
       "0   39  State-gov  Bachelors  Never-married  Adm-clerical  Not-in-family   \n",
       "\n",
       "    race   sex  hours-per-week native-country  \n",
       "0  White  Male              40  United-States  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###---------- run to test the model ---------\n",
    "# Define prediction labels.\n",
    "predict_labels = ['<=50K','>50K']\n",
    "\n",
    "# Load the model.\n",
    "LogisticRegression = load(open('logisticregression.pkl', 'rb'))\n",
    "\n",
    "# Load the scaler.\n",
    "scaler = load(open('scaler.pkl', 'rb'))\n",
    "\n",
    "# InputData\n",
    "input_row1 = [[39, \"State-gov\", \"Bachelors\", \"Never-married\", \"Adm-clerical\", \"Not-in-family\", \"White\", \"Male\", 40, \"United-States\"]] # <=50K\n",
    "# input_row2 = [[28, \"Private\", \"Bachelors\", \"Married-civ-spouse\", \"Prof-specialty\", \"Wife\", \"Black\", \"Female\", 40, \"Cuba\"]]  # <=50K\n",
    "\n",
    "\n",
    "input_row1_df = pd.DataFrame(input_row1, columns=[\"age\", \"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\",  \"race\", \"sex\", \"hours-per-week\", \"native-country\"]\n",
    ")\n",
    "input_row1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38fce06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode user input\n",
    "income_cat = ['workclass',\n",
    " 'education',\n",
    " 'marital-status',\n",
    " 'occupation',\n",
    " 'relationship',\n",
    " 'race',\n",
    " 'sex',\n",
    " 'native-country']\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(input_row1_df[income_cat]))\n",
    "\n",
    "# # Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(income_cat)\n",
    "\n",
    "# # Merge one-hot encoded features and drop the originals\n",
    "input_row1_df = input_row1_df.merge(encode_df, left_index=True, right_index=True).drop(income_cat,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae16275b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>education_Bachelors</th>\n",
       "      <th>marital-status_Never-married</th>\n",
       "      <th>occupation_Adm-clerical</th>\n",
       "      <th>relationship_Not-in-family</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>native-country_United-States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  hours-per-week  workclass_State-gov  education_Bachelors  \\\n",
       "0   39              40                  1.0                  1.0   \n",
       "\n",
       "   marital-status_Never-married  occupation_Adm-clerical  \\\n",
       "0                           1.0                      1.0   \n",
       "\n",
       "   relationship_Not-in-family  race_White  sex_Male  \\\n",
       "0                         1.0         1.0       1.0   \n",
       "\n",
       "   native-country_United-States  \n",
       "0                           1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_row1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d687711",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but StandardScaler is expecting 100 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-5ef818dbb788>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 2. Transform each input using the scaler function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_row1_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_row1_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"printing input row1 scaled: {input_row1_scaled}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# # 3. Make a prediction for each input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# predict = LogisticRegression.predict(input_row1_scaled)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m                                 force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m             raise ValueError(\n\u001b[1;32m--> 366\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 10 features, but StandardScaler is expecting 100 features as input."
     ]
    }
   ],
   "source": [
    "# 2. Transform each input using the scaler function.\n",
    "input_row1_scaled = scaler.transform(input_row1_df)\n",
    "print(f\"printing input row1 scaled: {input_row1_scaled}\")\n",
    "# 3. Make a prediction for each input.\n",
    "predict = LogisticRegression.predict(input_row1_scaled)\n",
    "print(f'Prediction 1 is: {predict_labels[predict[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9a112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
